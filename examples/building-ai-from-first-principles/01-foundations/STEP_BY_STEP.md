# Step-by-Step Tutorial Guide ğŸ“š

*Part 1: Foundation - Detailed Walkthrough*

This guide takes you through building your first AI components using the PocketFlow pattern. Follow along at your own pace!

> ğŸ§  **Remember Our Manifesto**: *"Complex AI systems are just simple ideas stacked together."* Today we'll prove this by transforming messy API calls into clean, reusable building blocks.

## ğŸ“š Tutorial Overview

We'll build three progressive examples:
1. **Basic Chat Completion** - Learn the pattern
2. **Interactive Terminal Chat** - Apply the pattern  
3. **Framework Comparison** - See the evolution

## Step 1: Understanding the PocketFlow Pattern ğŸ§±

Traditional AI code mixes everything together. PocketFlow separates concerns with a clear three-phase pattern:

```typescript
// âŒ Traditional approach - everything mixed together
async function chatbot(message: string) {
    const conversation = [];
    conversation.push({role: 'user', content: message});
    const response = await openai.complete(conversation);
    conversation.push({role: 'assistant', content: response});
    return conversation;
}

// âœ… PocketFlow approach - separated concerns
class ChatNode extends Node<SharedStorage> {
    // prep() runs first - it gets data ready for processing
    // SharedStorage is our "memory" - it persists across the entire conversation
    // We return Message[] which becomes the input to exec()
    async prep(shared: SharedStorage): Promise<Message[]> { 
        /* Extract & transform data from SharedStorage */ 
    }
    
    // exec() runs second - it does the main work (like calling the LLM)
    // It only sees what prep() returned, not the full SharedStorage
    // This isolation makes it easy to test and debug
    async exec(messages: Message[]): Promise<string> { 
        /* Process the data (isolated from storage) */ 
    }
    
    // post() runs last - it handles the results
    // It has access to SharedStorage again to save results
    // It can also access what prep() and exec() returned
    async post(shared: SharedStorage, prepResult: any, execResult: any): Promise<void> { 
        /* Load results back into SharedStorage */ 
    }
}
```

**ğŸŒ‰ Connecting the Dots**

**If you're coming from web development:** 
- prep() = Controller (handle request)
- exec() = Service (business logic)  
- post() = Response (send result)

**If you're coming from data science:**
- prep() = Data preprocessing
- exec() = Model inference
- post() = Post-processing results

**Key Insight:** This is like ETL (Extract, Transform, Load) for AI workflows - clean, testable, and scalable.

ğŸ” **Checkpoint**: Before continuing, make sure you understand:
- What SharedStorage represents (the "memory" of your AI system)
- Why we separate prep/exec/post (testability and clarity)
- How the three phases work together as a pipeline

> ğŸŒ± **First Principles Thinking**: Each phase has ONE job. When you understand each simple piece, the complex system becomes clear.

Need clarification? See [JOIN_COMMUNITY.md](../JOIN_COMMUNITY.md) - fellow builders are ready to help!

## Step 2: Shared Storage - The Memory Center ğŸ§ 

Everything in PocketFlow revolves around the `SharedStorage` object that travels through your entire flow:

```typescript
type SharedStorage = {
    messages: Message[];  // Conversation history
    userMessage: string;  // Current user input
    // Later we might add: context, metadata, user_data, etc.
}
```

This is the "memory" of your AI system - the center of everything in PocketFlow.

```mermaid
graph TD
    S["SharedStorage<br/>(Center of Everything)"]
    S <--> P["prep()<br/>reads & writes"]
    P --> E["exec()<br/>isolated"]
    S <--> Po["post()<br/>reads & writes"]
    
    classDef storage fill:#fff3e0,stroke:#f57c00,stroke-width:3px
    classDef connected fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef isolated fill:#ffebee,stroke:#c62828,stroke-width:2px
    
    class S storage
    class P,Po connected
    class E isolated
```

**ğŸ’¡ Think of it like a notebook:**
- prep() reads the notebook and prepares data for processing
- exec() gets a copy of the prepared data (but can't modify the notebook)
- post() writes results back into the notebook

## Step 3: Building Your First ChatNode ğŸ”§

Let's build a ChatNode step by step. Open `examples/basic-chat.ts` and follow along:

### The Complete Implementation

```typescript
// ğŸ¤– PocketFlow Node that handles the chat completion
class ChatNode extends Node<SharedStorage> {
    private debug = process.env.DEBUG_CHAT === 'true';

    // ğŸ¯ PREP: Transform SharedStorage into what exec() needs
    async prep(shared: SharedStorage): Promise<Message[]> {
        if (this.debug) console.log('ğŸ” PREP: Adding user message to conversation');
        
        // Add the user's message to our conversation history
        shared.messages.push({ role: 'user', content: shared.userMessage });
        
        if (this.debug) console.log(`ğŸ” PREP: Conversation now has ${shared.messages.length} messages`);
        
        // Return the full conversation - this becomes exec()'s input
        return shared.messages;
    }
    
    // âš¡ EXEC: Do the main work (isolated from SharedStorage)
    async exec(messages: Message[]): Promise<string> {
        if (this.debug) console.log('ğŸ” EXEC: Calling LLM with messages:', messages.length);
        
        try {
            const response = await callLLM(messages);
            if (this.debug) console.log('ğŸ” EXEC: Got response from LLM');
            return response;
        } catch (error) {
            console.error('âŒ EXEC: LLM call failed:', error instanceof Error ? error.message : 'Unknown error');
            throw error;
        }
    }
    
    // ğŸ’¾ POST: Handle the results and update SharedStorage
    async post(shared: SharedStorage, prepRes: unknown, execRes: unknown): Promise<string | undefined> {
        if (this.debug) console.log('ğŸ” POST: Storing AI response in SharedStorage');
        
        // Add AI response to shared storage for future conversations
        shared.messages.push({ 
            role: 'assistant', 
            content: execRes as string 
        });
        
        if (this.debug) console.log(`ğŸ” POST: Conversation now has ${shared.messages.length} messages`);
        
        // Return undefined to end the flow (no next node)
        return undefined;
    }
}
```

### Running Your First Example

**ğŸš€ Try it yourself:**
```bash
# Run the basic chat completion example
npx tsx examples/basic-chat.ts

# Want to see what's happening step by step?
DEBUG_CHAT=true npx tsx examples/basic-chat.ts
```

**Expected output:**
```
ğŸ“ Chat Completion - PocketFlow Basics

ğŸƒ Running the flow...
ğŸ“ User message: "Explain the ETL process in a few sentences. Reply in markdown format."

ğŸ’¬ Conversation Result:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. ğŸ‘¤ user: Explain the ETL process in a few sentences. Reply in markdown format.

2. ğŸ¤– assistant: # ETL Process

**ETL** stands for **Extract, Transform, Load** - a fundamental data processing pattern:

- **Extract**: Pull data from various sources (databases, APIs, files)
- **Transform**: Clean, validate, and restructure the data as needed  
- **Load**: Insert the processed data into a target system (warehouse, database)

This pattern ensures data quality and consistency across systems.

âœ… Tutorial complete!

ğŸ’¡ What just happened (the PocketFlow pattern):
   ğŸ¯ prep() - Added user message to SharedStorage
   âš¡ exec() - Called OpenAI with the conversation
   ğŸ’¾ post() - Stored AI response back in SharedStorage

ğŸš€ Ready for interactive chat? Try: npx tsx examples/interactive-chat.ts
ğŸ”§ Want to see debug info? Try: DEBUG_CHAT=true npx tsx examples/basic-chat.ts
```

**What you'll notice:**
- The response shows how **prep** added your message to the conversation
- The **exec** phase called the LLM with the conversation history  
- The **post** phase stored the AI's response back in SharedStorage

ğŸ” **Checkpoint**: Before continuing, make sure you can:
- Run the example without errors
- Understand what each phase (prep/exec/post) does
- See how SharedStorage accumulates conversation state

## Step 4: From Single Chat to Interactive Conversation ğŸ’¬

Now let's see how the same ChatNode powers an interactive conversation. The beauty of the pattern is that **the same node works for both single interactions and ongoing conversations**.

### The Terminal Chat Implementation

Open `examples/interactive-chat.ts` and you'll see:

```typescript
class TerminalChat {
    private shared: SharedStorage = { messages: [] };  // Persistent memory
    
    async processUserInput(input: string) {
        // Use the same ChatNode pattern for each interaction
        const response = await sendMessage(this.shared, input);
        // SharedStorage accumulates conversation history automatically!
    }
}
```

**Key insight**: The same ChatNode that handled one message can handle an entire conversation because SharedStorage persists between interactions.

### ğŸ¬ Flow Visualization

Watch what happens step by step:

**First interaction:**
```
prep() â†’ "Hello" added to SharedStorage â†’ messages: [user: "Hello"]
  â†“
exec() â†’ LLM processes [user: "Hello"] â†’ returns "Hi there!"
  â†“  
post() â†’ "Hi there!" added to SharedStorage â†’ messages: [user: "Hello", assistant: "Hi there!"]
```

**Second interaction:**
```
prep() â†’ "How are you?" added to SharedStorage â†’ messages: [user: "Hello", assistant: "Hi there!", user: "How are you?"]
  â†“
exec() â†’ LLM processes full conversation â†’ returns "I'm doing well, thanks!"
  â†“  
post() â†’ Response added â†’ messages: [user: "Hello", assistant: "Hi there!", user: "How are you?", assistant: "I'm doing well, thanks!"]
```

**ğŸš€ Try the interactive version:**
```bash
npx tsx examples/interactive-chat.ts
```

ğŸ” **Checkpoint**: Before continuing, make sure you understand:
- How the same ChatNode works for both examples
- Why SharedStorage accumulates conversation history
- How prepâ†’execâ†’post keeps working regardless of complexity

> ğŸ”„ **Building Systematically**: One pattern, infinite applications. This is how we'll build entire AI ecosystems - one reusable piece at a time.

### Expected Interactive Experience

```
ğŸš€ Welcome to PocketFlow Terminal Chat!
ğŸ’¬ Type your messages and press Enter to chat with AI
ğŸ”š Type "exit", "quit", or "bye" to end the conversation
ğŸ“œ Type "history" to see the full conversation
ğŸ§¹ Type "clear" to clear the conversation history
--------------------------------------------------

ğŸ’¬ You: Hello! How does PocketFlow work?
ğŸ¤– AI is thinking...
ğŸ‘¤ You: Hello! How does PocketFlow work?
ğŸ¤– AI: PocketFlow works by organizing AI workflows into three clean phases: prep (organize data), exec (do the work), and post (handle results). This pattern makes your AI code more testable, debuggable, and reusable than traditional approaches.

ğŸ’¬ You: What's the benefit of SharedStorage?
ğŸ¤– AI is thinking...
ğŸ‘¤ You: What's the benefit of SharedStorage?
ğŸ¤– AI: SharedStorage acts as the persistent memory of your AI system - it maintains conversation history, context, and state across multiple interactions, unlike stateless API calls that forget everything between requests.

ğŸ’¬ You: history
ğŸ“œ Conversation History:
------------------------------
1. ğŸ‘¤ You: Hello! How does PocketFlow work?
2. ğŸ¤– AI: PocketFlow works by organizing AI workflows...
3. ğŸ‘¤ You: What's the benefit of SharedStorage?  
4. ğŸ¤– AI: SharedStorage acts as the persistent memory...
------------------------------

ğŸ’¬ You: exit
ğŸ‘‹ Thanks for chatting! Goodbye!
```

**Key observation:** Notice how the AI remembers previous messages - this is **SharedStorage** in action!

## Step 5: Understanding the Pattern Benefits ğŸ†

### Why This Pattern Matters

```typescript
// âŒ Traditional mixed approach
async function traditionalChat(message: string) {
    // Everything mixed together - hard to test, debug, or extend
    const conversation = getConversation();
    conversation.push({role: 'user', content: message});
    const response = await openai.complete(conversation);
    conversation.push({role: 'assistant', content: response});
    saveConversation(conversation);
    return response;
}

// âœ… PocketFlow separated approach  
class ChatNode extends Node<SharedStorage> {
    async prep(shared) { 
        // Easy to test: just pass mock SharedStorage
        // Easy to debug: isolate data preparation issues
    }
    async exec(messages) { 
        // Easy to test: just pass mock messages
        // Easy to debug: isolate LLM call issues
    }
    async post(shared, prep, exec) { 
        // Easy to test: pass mock results
        // Easy to debug: isolate storage issues
    }
}
```

### The Pattern Enables

âœ… **Testing**: Mock each phase independently  
âœ… **Debugging**: Know exactly where failures occur  
âœ… **Reusability**: Same node works in different flows  
âœ… **Extensibility**: Add features without breaking existing code  
âœ… **Clarity**: Each phase has a single responsibility  

## Step 6: Practice and Experimentation ğŸª

**Ready to experiment?** Try these modifications:

### Quick Modifications

1. **Add timestamps**: 
```typescript
type Message = {
    role: 'user' | 'assistant';
    content: string;
    timestamp: Date; // Add this!
}
```

2. **Conversation limits**:
```typescript
async prep(shared: SharedStorage): Promise<Message[]> {
    // Add user message
    shared.messages.push({ role: 'user', content: shared.userMessage });
    
    // Keep only last 10 messages
    if (shared.messages.length > 10) {
        shared.messages = shared.messages.slice(-10);
    }
    
    return shared.messages;
}
```

3. **Debug mode**: 
```bash
DEBUG_CHAT=true npx tsx examples/basic-chat.ts
```

### Understanding Check

Before moving on, make sure you can answer:

1. **What happens if you remove the `post()` method?** (Try it!)
2. **How would you add a system message?** (Hint: always ensure it's first)
3. **Why is `exec()` isolated from SharedStorage?** (Think about testing)

**Want more challenges?** Check out [EXERCISES.md](./EXERCISES.md) for guided practice!

## ğŸ¯ Summary: What You've Learned

By completing this tutorial, you now understand:

âœ… **The PocketFlow Pattern**: prepâ†’execâ†’post for clean AI workflows  
âœ… **SharedStorage**: The "memory" that persists across interactions  
âœ… **Node Reusability**: Same component works for single calls and conversations  
âœ… **Error Handling**: How to build robust AI applications  
âœ… **Framework Thinking**: How patterns enable scalable systems  

## ğŸš€ Ready for More?

**Next steps:**
1. **Practice**: Try the [EXERCISES.md](./EXERCISES.md) challenges
2. **Explore**: Read [CONCEPTS_DEEP_DIVE.md](./CONCEPTS_DEEP_DIVE.md) for framework evolution
3. **Build**: Apply the pattern to your own AI ideas
4. **Continue**: Move to Part 2 - Research Agent

**Questions or stuck?** Check [TROUBLESHOOTING.md](./TROUBLESHOOTING.md) or see [JOIN_COMMUNITY.md](../JOIN_COMMUNITY.md) for help!

> ğŸ“š **Creating Lasting Value**: You're not just learning - you're building components that will power future AI applications. Share your progress in the community and inspire others!

---

[â† **Back to Overview**](./README.md) | [**Deep Dive Concepts** â†’](./CONCEPTS_DEEP_DIVE.md) | [**Practice Exercises** â†’](./EXERCISES.md)
